# **\[EMNLP 2025\]** Mitigating Object Hallucinations in MLLMs via Multi-Frequency Perturbations
<img width="2442" height="804" alt="image" src="https://github.com/user-attachments/assets/c06ce866-b75e-4e02-9a9f-e1e053b8f3d9" />

## Quick Start
Our codebase and environment configuration using [llava](https://github.com/haotian-liu/LLaVA). Most of our changes are in the [clip_encoder.py](https://github.com/galactic123/MFP/blob/main/llava/model/multimodal_encoder/clip_encoder.py) file.

## Citation
```
@inproceedings{li-etal-2025-mitigating-object,
    title = "Mitigating Object Hallucinations in {MLLM}s via Multi-Frequency Perturbations",
    author = "Li, Shuo  and
      Sun, Jiajun  and
      Zheng, Guodong  and
      Fan, Xiaoran  and
      Shen, Yujiong  and
      Lu, Yi  and
      Xi, Zhiheng  and
      Yang, Yuming  and
      Tan, Wenming  and
      Ji, Tao  and
      Gui, Tao  and
      Zhang, Qi  and
      Huang, Xuanjing",
    editor = "Christodoulopoulos, Christos  and
      Chakraborty, Tanmoy  and
      Rose, Carolyn  and
      Peng, Violet",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2025",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-emnlp.64/",
    doi = "10.18653/v1/2025.findings-emnlp.64",
    pages = "1230--1247",
    ISBN = "979-8-89176-335-7",
    abstract = "Recently, multimodal large language models (MLLMs) have demonstrated remarkable performance in visual-language tasks. However, the authenticity of the responses generated by MLLMs is often compromised by object hallucinations. We identify that a key cause of these hallucinations is the model{'}s over-susceptibility to image frequency features in detecting objects. In this paper, we introduce Multi-Frequency Perturbations (MFP), a simple, cost-effective, and pluggable adversarial training method that leverages both low-frequency and high-frequency features of images to perturb visual feature representations and explicitly suppress redundant frequency-domain features during inference, thereby mitigating hallucinations. Experimental results demonstrate that our method significantly mitigates object hallucinations across various model architectures. Furthermore, as a training-time method, MFP can be combined with inference-time methods to achieve state-of-the-art performance on the CHAIR benchmark."
}
```
